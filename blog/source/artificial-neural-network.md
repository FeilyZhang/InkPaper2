title: "人工神经网络"
date: 2019-03-26 15:55:25 +0800
update: 2019-03-26 15:55:25 +0800
author: me
cover: "-/images/article/shenjingyuan.jpg"
tags:
    - Machine Learning
preview: 决策树学习算法以树形结构建立模型，类似于流程图，该模型本身包含一系列逻辑决策。

---

## 一、从生物神经网络到人工神经网络
如同人脑使用一个被称为神经元的相互连接的细胞网络来创建一个巨大的并行处理器一样，人工神经网络使用人工神经元或节点的网络来解决学习问题。既然，人工神经网络基于生物神经网络，那么有必要了解一下生物神经细胞或神经元的组成。

### 1.1 生物神经网络

![神经元结构图](/images/article/shenjingyuan.jpg)

如上图所示，每个神经元由包含一个细胞核的一个细胞体组成。从细胞体分支扩展出许多被称为**树突**的神经纤维和一根长的称为**轴突**的神经纤维。其中，树突接受神经冲动作为神经元的输入信号，但神经元并非对所有的神经冲动进行处理，而是在神经冲动信号达到一个阈值后才会处理并将输出信号通过轴突传递给下层神经元。**突触**则是神经元的连接，与轴突相区分，突触包含以下三种：

+ 轴突-树突突触：一个神经元的轴突与下一个神经元的树突相连；
+ 轴突-胞体突触：一个神经元的轴突与下一个神经元的胞体相连；
+ 轴突-轴突突触：一个神经元的轴突与下一个神经元的轴突相连；

![突触示意图](/images/article/tuchu.jpg)

神经元对神经信号的处理是有条件的，即必须达到一个阈值。如何判断呢？答案是通过神经冲动相对重要性或频率的加权和。如果加权和达到该阈值，那么神经元将会处理(激活)该神经信号，否则不予理会。事实上，每个神经元都是这么干的。那么直观上，神经元的功能就是**求和**与**激活**。

### 1.2 人工神经网络
人工神经网络作为生物神经网络的仿真，那么将概念迁移过来，首先图示如下

![神经元对比示意图](/images/article/artificial-neural.png)

可以看出，一个有向网络图定义了神经元对输入信号(变量X)的接收，每个特征对应一个输入，每个输入连向神经元的有向线段上表明了该信号的权重，那么众多输入信号在每个神经元处首先被加权求和，然后将加权和结果作为神经元激活函数的自变量就可以得到该神经元的输出，该输出将会作为下一个神经元的输入，下一个神经元仍然会进行同样的加权求和和激活操作。

一个典型的具有n个输入树突的神经元可以用如下公式来表示

![具备n个输入的神经元](/images/article/sum-function.png)

其中，权重w可以控制n个输入(x)中的每个输入对输入信号之和所做出贡献的大小。激活函数f(x)使用净总和，结果信号y(x)就是输出轴突。

定义一个人工神经网络，需要具备三个概念，如下

+ **激活函数**：将神经元的净输入(加权和)信号转化为单一的输出信号，以便进一步在网络中传播；
+ **网络拓扑**：描述神经网络中神经元的数目及层数以及它们之间的连接方式；
+ **训练算法**：指定如何设置连接权重，以便抑制或者增加神经元在输入信号中的比重。

它们之间的关系为，**网络拓扑**由一层层神经元组成，每层包含若干个神经元，这些(不同层)神经元组成了人工神经网络的基本骨架；其中每个神经元都会进行加权求和与激活操作，实质上就是每个神经元通过自己的**激活函数**将净输入转化为输出(如上面的公式所示)，以便进一步传播。

我们假设通过一种被称为**后向传播算法**的算法来训练神经网络，该算法通过两个过程的多次循环进行迭代，每次迭代称为一个**新纪元**。由于初始的神经网络里面不包含先验知识，所以在开始之前先随机设定网络拓扑中每个输入的权重，然后算法通过过程循环，直到达到一个停止准则。该循环过程包括：

+ 在前向阶段中，神经元在输入层到输出层的序列中被激活，沿途应用每一个神经元的权重和激活函数，一旦到达最后一层，就产生一个输出信号。
+ 在后向阶段中，由前向阶段产生的网络输出信号与训练数据中的真实目标值进行比较，网络的输出信号与真实目标值之间的差异产生的误差在网络中向后传播，从而来修正神经元之间的连接权重，从而减少神经网络最终输出值与训练集数据目标值的误差。

但是，每个神经元的输入与输出之间的关系很复杂，我们又如何确定神经元的权重该改变多少呢？

答案是通过**梯度下降算法**来实现。在后向传播算法的后向阶段，我们修正神经元的核心技术就是通过梯度下降算法最小化我们的成本函数**J(w, b)**,对应的就是求由w、b以及目标成本函数J(w, b)构成的三维曲面的最低点，也就是成本函数的最小值。

![成本函数最小值](/images/article/chengbenhanshu.png)

可以看出，该算法试图通过一个称为学习率(或步长)的量来改变权重以使得误差最大化的减小。学习率学大，算法训练的越快但是风险就是可能会错过合适的权重，学习率学校，好处是不会错过合适的权重，但是训练时间长。